{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext bigdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pig_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeout 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Se crea el directorio de entrada\n",
    "##!rm -rf input output\n",
    "#!mkdir input\n",
    "!rm -rf output\n",
    "!mkdir output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\n",
      "-rw-r--r--   1 root supergroup        615 2020-01-30 02:29 data.csv\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -put *.csv .\n",
    "!hadoop fs -ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " u = LOAD 'data.csv' USING PigStorage(',') \n",
      "    AS (id:int, \n",
      "        firstname:CHARARRAY, \n",
      "        surname:CHARARRAY, \n",
      "        birthday:CHARARRAY, \n",
      "        color:CHARARRAY, \n",
      "        quantity:INT);\n",
      " s = GROUP u BY id;\n",
      " r5 = FOREACH s GENERATE group, COUNT(u.id);\n",
      " DUMP r5;\n",
      "2020-01-30 02:34:24,647 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-01-30 02:34:26,143 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-01-30 02:34:26,155 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-01-30 02:34:26,166 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-01-30 02:34:27,144 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-01-30 02:34:27,198 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1580350921464_0003\n",
      "2020-01-30 02:34:27,201 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2020-01-30 02:34:27,240 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1580350921464_0003\n",
      "2020-01-30 02:34:27,244 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://4f466a1273a4:8088/proxy/application_1580350921464_0003/\n",
      "2020-01-30 02:34:47,495 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-01-30 02:34:47,510 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-01-30 02:34:47,607 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-01-30 02:34:47,612 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-01-30 02:34:47,646 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-01-30 02:34:47,650 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-01-30 02:34:47,683 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-01-30 02:34:47,687 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-01-30 02:34:47,712 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-01-30 02:34:47,716 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-01-30 02:34:47,744 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-01-30 02:34:47,748 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-01-30 02:34:47,802 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "(1,1)\n",
      "(2,1)\n",
      "(3,1)\n",
      "(4,1)\n",
      "(5,1)\n",
      "(6,1)\n",
      "(7,1)\n",
      "(8,1)\n",
      "(9,1)\n",
      "(10,1)\n",
      "(11,1)\n",
      "(12,1)\n",
      "(13,1)\n",
      "(14,1)\n",
      "(15,1)\n",
      "(16,1)\n",
      "(17,1)\n",
      "(18,1)\n",
      " --STORE r5 INTO 'output';\n",
      " --fs -get output/ .;\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "u = LOAD 'data.csv' USING PigStorage(',') \n",
    "    AS (id:int, \n",
    "        firstname:CHARARRAY, \n",
    "        surname:CHARARRAY, \n",
    "        birthday:CHARARRAY, \n",
    "        color:CHARARRAY, \n",
    "        quantity:INT);\n",
    "s = GROUP u BY id;\n",
    "r5 = FOREACH s GENERATE group, COUNT(u.id);\n",
    "DUMP r5;\n",
    "--STORE r5 INTO 'output';\n",
    "--fs -get output/ .;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " u = LOAD 'data.csv' USING PigStorage(',') \n",
      "    AS (id:int, \n",
      "        firstname:CHARARRAY, \n",
      "        surname:CHARARRAY, \n",
      "        birthday:CHARARRAY, \n",
      "        color:CHARARRAY, \n",
      "        quantity:INT);\n",
      " col = FOREACH u GENERATE birthday, SUBSTRING(birthday,7,8) as val;\n",
      " c = FILTER col BY (birthday MATCHES '^{1}{9}[0-9][0-9]');\n",
      " d = FILTER col BY (birthday MATCHES '^{1}{9}[0-9][0-9]');\n",
      " l = FOREACH c GENERATE $0;\n",
      " DUMP l;\n",
      "2020-01-30 03:37:14,081 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-01-30 03:37:14,297 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-01-30 03:37:14,304 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-01-30 03:37:14,313 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-01-30 03:37:14,349 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-01-30 03:37:14,873 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1580350921464_0022\n",
      "2020-01-30 03:37:14,879 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2020-01-30 03:37:15,107 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1580350921464_0022\n",
      "2020-01-30 03:37:15,109 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://4f466a1273a4:8088/proxy/application_1580350921464_0022/\n",
      "2020-01-30 03:37:35,278 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-01-30 03:37:35,282 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-01-30 03:37:35,367 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-01-30 03:37:35,370 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-01-30 03:37:35,396 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-01-30 03:37:35,398 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-01-30 03:37:35,430 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-01-30 03:37:35,432 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-01-30 03:37:35,468 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-01-30 03:37:35,471 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-01-30 03:37:35,489 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-01-30 03:37:35,491 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-01-30 03:37:35,513 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      " --STORE c INTO 'output' USING PigStorage(',');\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "u = LOAD 'data.csv' USING PigStorage(',') \n",
    "    AS (id:int, \n",
    "        firstname:CHARARRAY, \n",
    "        surname:CHARARRAY, \n",
    "        birthday:CHARARRAY, \n",
    "        color:CHARARRAY, \n",
    "        quantity:INT);\n",
    "col = FOREACH u GENERATE birthday, SUBSTRING(birthday,7,8) as val;\n",
    "c = FILTER col BY (birthday MATCHES '^{1}{9}[0-9][0-9]');\n",
    "d = FILTER col BY (birthday MATCHES '^{1}{9}[0-9][0-9]');\n",
    "l = FOREACH c GENERATE $0;\n",
    "DUMP l;\n",
    "--STORE c INTO 'output' USING PigStorage(',');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
