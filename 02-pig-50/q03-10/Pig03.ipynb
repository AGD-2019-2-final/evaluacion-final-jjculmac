{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bigdata extension is already loaded. To reload it, use:\n",
      "  %reload_ext bigdata\n"
     ]
    }
   ],
   "source": [
    "%load_ext bigdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pig_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeout 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Se crea el directorio de entrada\n",
    "##!rm -rf input output\n",
    "##!mkdir input\n",
    "!rm -rf output\n",
    "!mkdir output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "put: Call From 5c3c4ff8be60/172.17.0.2 to 0.0.0.0:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n",
      "ls: Call From 5c3c4ff8be60/172.17.0.2 to 0.0.0.0:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -put *.tsv .\n",
    "!hadoop fs -ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " u = LOAD 'data.tsv' AS (f1:CHARARRAY, f2:CHARARRAY, f3:INT);\n",
      "2020-01-15 04:01:13,969 [main] WARN  org.apache.hadoop.ipc.Client - Failed to connect to server: 0.0.0.0/0.0.0.0:9000: try once and fail.\n",
      "java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:685)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:788)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1381)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1345)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)\n",
      "\tat com.sun.proxy.$Proxy10.getFileInfo(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:796)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)\n",
      "\tat com.sun.proxy.$Proxy11.getFileInfo(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1649)\n",
      "\tat org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1440)\n",
      "\tat org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1437)\n",
      "\tat org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\n",
      "\tat org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1437)\n",
      "\tat org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1437)\n",
      "\tat org.apache.pig.backend.hadoop.datastorage.HDataStorage.isContainer(HDataStorage.java:216)\n",
      "\tat org.apache.pig.backend.hadoop.datastorage.HDataStorage.asElement(HDataStorage.java:132)\n",
      "\tat org.apache.pig.backend.hadoop.datastorage.HDataStorage.asElement(HDataStorage.java:143)\n",
      "\tat org.apache.pig.parser.QueryParserUtils.getCurrentDir(QueryParserUtils.java:93)\n",
      "\tat org.apache.pig.parser.LogicalPlanBuilder.buildLoadOp(LogicalPlanBuilder.java:896)\n",
      "\tat org.apache.pig.parser.LogicalPlanGenerator.load_clause(LogicalPlanGenerator.java:3568)\n",
      "\tat org.apache.pig.parser.LogicalPlanGenerator.op_clause(LogicalPlanGenerator.java:1625)\n",
      "\tat org.apache.pig.parser.LogicalPlanGenerator.general_statement(LogicalPlanGenerator.java:1102)\n",
      "\tat org.apache.pig.parser.LogicalPlanGenerator.statement(LogicalPlanGenerator.java:560)\n",
      "\tat org.apache.pig.parser.LogicalPlanGenerator.query(LogicalPlanGenerator.java:421)\n",
      "\tat org.apache.pig.parser.QueryParserDriver.parse(QueryParserDriver.java:191)\n",
      "\tat org.apache.pig.PigServer$Graph.validateQuery(PigServer.java:1792)\n",
      "\tat org.apache.pig.PigServer$Graph.registerQuery(PigServer.java:1765)\n",
      "\tat org.apache.pig.PigServer.registerQuery(PigServer.java:708)\n",
      "\tat org.apache.pig.tools.grunt.GruntParser.processPig(GruntParser.java:1110)\n",
      "\tat org.apache.pig.tools.pigscript.parser.PigScriptParser.parse(PigScriptParser.java:512)\n",
      "\tat org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:230)\n",
      "\tat org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:205)\n",
      "\tat org.apache.pig.tools.grunt.Grunt.run(Grunt.java:66)\n",
      "\tat org.apache.pig.Main.run(Main.java:564)\n",
      "\tat org.apache.pig.Main.main(Main.java:175)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.util.RunJar.run(RunJar.java:239)\n",
      "\tat org.apache.hadoop.util.RunJar.main(RunJar.java:153)\n",
      "2020-01-15 04:01:14,000 [main] ERROR org.apache.pig.tools.grunt.Grunt - ERROR 6007: Unable to check name hdfs://0.0.0.0:9000/user/root\n",
      "Details at logfile: /datalake/evaluacion-final-jjculmac-master/02-pig-50/q03-10/pig_1579060858033.log\n",
      " t = FOREACH u GENERATE $2;\n",
      "2020-01-15 04:01:14,122 [main] ERROR org.apache.pig.tools.grunt.Grunt - ERROR 1200: Pig script failed to parse: <line 1, column 12> Undefined alias: u\n",
      "Details at logfile: /datalake/evaluacion-final-jjculmac-master/02-pig-50/q03-10/pig_1579060858033.log\n",
      " s = ORDER t BY f3;\n",
      "2020-01-15 04:01:14,210 [main] ERROR org.apache.pig.tools.grunt.Grunt - ERROR 1200: Pig script failed to parse: <line 1, column 10> Undefined alias: t\n",
      "Details at logfile: /datalake/evaluacion-final-jjculmac-master/02-pig-50/q03-10/pig_1579060858033.log\n",
      " y = LIMIT s 5;\n",
      "2020-01-15 04:01:14,287 [main] ERROR org.apache.pig.tools.grunt.Grunt - ERROR 1200: Pig script failed to parse: <line 1, column 10> Undefined alias: s\n",
      "Details at logfile: /datalake/evaluacion-final-jjculmac-master/02-pig-50/q03-10/pig_1579060858033.log\n",
      " DUMP y;\n",
      "2020-01-15 04:01:14,378 [main] WARN  org.apache.hadoop.ipc.Client - Failed to connect to server: 0.0.0.0/0.0.0.0:9000: try once and fail.\n",
      "java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:685)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:788)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1381)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1345)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)\n",
      "\tat com.sun.proxy.$Proxy10.getFileInfo(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:796)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)\n",
      "\tat com.sun.proxy.$Proxy11.getFileInfo(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1649)\n",
      "\tat org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1440)\n",
      "\tat org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1437)\n",
      "\tat org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\n",
      "\tat org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1437)\n",
      "\tat org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1437)\n",
      "\tat org.apache.pig.backend.hadoop.datastorage.HPath.exists(HPath.java:106)\n",
      "\tat org.apache.pig.impl.io.FileLocalizer.getTempContainer(FileLocalizer.java:499)\n",
      "\tat org.apache.pig.impl.io.FileLocalizer.relativeRoot(FileLocalizer.java:467)\n",
      "\tat org.apache.pig.impl.io.FileLocalizer.getTemporaryPath(FileLocalizer.java:549)\n",
      "\tat org.apache.pig.impl.io.FileLocalizer.getTemporaryPath(FileLocalizer.java:545)\n",
      "\tat org.apache.pig.PigServer.openIterator(PigServer.java:995)\n",
      "\tat org.apache.pig.tools.grunt.GruntParser.processDump(GruntParser.java:782)\n",
      "\tat org.apache.pig.tools.pigscript.parser.PigScriptParser.parse(PigScriptParser.java:383)\n",
      "\tat org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:230)\n",
      "\tat org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:205)\n",
      "\tat org.apache.pig.tools.grunt.Grunt.run(Grunt.java:66)\n",
      "\tat org.apache.pig.Main.run(Main.java:564)\n",
      "\tat org.apache.pig.Main.main(Main.java:175)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.util.RunJar.run(RunJar.java:239)\n",
      "\tat org.apache.hadoop.util.RunJar.main(RunJar.java:153)\n",
      "2020-01-15 04:01:14,419 [main] WARN  org.apache.hadoop.ipc.Client - Failed to connect to server: 0.0.0.0/0.0.0.0:9000: try once and fail.\n",
      "java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:685)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:788)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1381)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1345)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)\n",
      "\tat com.sun.proxy.$Proxy10.mkdirs(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.mkdirs(ClientNamenodeProtocolTranslatorPB.java:583)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)\n",
      "\tat com.sun.proxy.$Proxy11.mkdirs(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2472)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.mkdirs(DFSClient.java:2447)\n",
      "\tat org.apache.hadoop.hdfs.DistributedFileSystem$25.doCall(DistributedFileSystem.java:1159)\n",
      "\tat org.apache.hadoop.hdfs.DistributedFileSystem$25.doCall(DistributedFileSystem.java:1156)\n",
      "\tat org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\n",
      "\tat org.apache.hadoop.hdfs.DistributedFileSystem.mkdirsInternal(DistributedFileSystem.java:1156)\n",
      "\tat org.apache.hadoop.hdfs.DistributedFileSystem.mkdirs(DistributedFileSystem.java:1148)\n",
      "\tat org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:1914)\n",
      "\tat org.apache.pig.backend.hadoop.datastorage.HDirectory.create(HDirectory.java:63)\n",
      "\tat org.apache.pig.backend.hadoop.datastorage.HPath.create(HPath.java:164)\n",
      "\tat org.apache.pig.impl.io.FileLocalizer.createContainer(FileLocalizer.java:517)\n",
      "\tat org.apache.pig.impl.io.FileLocalizer.getTempContainer(FileLocalizer.java:507)\n",
      "\tat org.apache.pig.impl.io.FileLocalizer.relativeRoot(FileLocalizer.java:467)\n",
      "\tat org.apache.pig.impl.io.FileLocalizer.getTemporaryPath(FileLocalizer.java:549)\n",
      "\tat org.apache.pig.impl.io.FileLocalizer.getTemporaryPath(FileLocalizer.java:545)\n",
      "\tat org.apache.pig.PigServer.openIterator(PigServer.java:995)\n",
      "\tat org.apache.pig.tools.grunt.GruntParser.processDump(GruntParser.java:782)\n",
      "\tat org.apache.pig.tools.pigscript.parser.PigScriptParser.parse(PigScriptParser.java:383)\n",
      "\tat org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:230)\n",
      "\tat org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:205)\n",
      "\tat org.apache.pig.tools.grunt.Grunt.run(Grunt.java:66)\n",
      "\tat org.apache.pig.Main.run(Main.java:564)\n",
      "\tat org.apache.pig.Main.main(Main.java:175)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.util.RunJar.run(RunJar.java:239)\n",
      "\tat org.apache.hadoop.util.RunJar.main(RunJar.java:153)\n",
      "2020-01-15 04:01:14,426 [main] ERROR org.apache.pig.tools.grunt.Grunt - ERROR 1066: Unable to open iterator for alias y\n",
      "Details at logfile: /datalake/evaluacion-final-jjculmac-master/02-pig-50/q03-10/pig_1579060858033.log\n",
      " STORE y INTO 'output';\n",
      "2020-01-15 04:01:14,511 [main] ERROR org.apache.pig.tools.grunt.Grunt - ERROR 1200: Pig script failed to parse: <line 1, column 6> Undefined alias: y\n",
      "Details at logfile: /datalake/evaluacion-final-jjculmac-master/02-pig-50/q03-10/pig_1579060858033.log\n",
      " fs -get output/ .;\n",
      "2020-01-15 04:01:14,786 [main] WARN  org.apache.hadoop.ipc.Client - Failed to connect to server: 0.0.0.0/0.0.0.0:9000: try once and fail.\n",
      "java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:685)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:788)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1381)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1345)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)\n",
      "\tat com.sun.proxy.$Proxy10.getFileInfo(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:796)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)\n",
      "\tat com.sun.proxy.$Proxy11.getFileInfo(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1649)\n",
      "\tat org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1440)\n",
      "\tat org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1437)\n",
      "\tat org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\n",
      "\tat org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1437)\n",
      "\tat org.apache.hadoop.fs.Globber.getFileStatus(Globber.java:64)\n",
      "\tat org.apache.hadoop.fs.Globber.doGlob(Globber.java:269)\n",
      "\tat org.apache.hadoop.fs.Globber.glob(Globber.java:148)\n",
      "\tat org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1686)\n",
      "\tat org.apache.hadoop.fs.shell.PathData.expandAsGlob(PathData.java:326)\n",
      "\tat org.apache.hadoop.fs.shell.Command.expandArgument(Command.java:245)\n",
      "\tat org.apache.hadoop.fs.shell.Command.expandArguments(Command.java:228)\n",
      "\tat org.apache.hadoop.fs.shell.FsCommand.processRawArguments(FsCommand.java:103)\n",
      "\tat org.apache.hadoop.fs.shell.Command.run(Command.java:175)\n",
      "\tat org.apache.hadoop.fs.FsShell.run(FsShell.java:317)\n",
      "\tat org.apache.pig.tools.grunt.GruntParser.processFsCommand(GruntParser.java:1173)\n",
      "\tat org.apache.pig.tools.pigscript.parser.PigScriptParser.parse(PigScriptParser.java:136)\n",
      "\tat org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:230)\n",
      "\tat org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:205)\n",
      "\tat org.apache.pig.tools.grunt.Grunt.run(Grunt.java:66)\n",
      "\tat org.apache.pig.Main.run(Main.java:564)\n",
      "\tat org.apache.pig.Main.main(Main.java:175)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.util.RunJar.run(RunJar.java:239)\n",
      "\tat org.apache.hadoop.util.RunJar.main(RunJar.java:153)\n",
      "get: Call From 5c3c4ff8be60/172.17.0.2 to 0.0.0.0:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "u = LOAD 'data.tsv' AS (f1:CHARARRAY, f2:CHARARRAY, f3:INT);\n",
    "t = FOREACH u GENERATE $2;\n",
    "s = ORDER t BY f3;\n",
    "y = LIMIT s 5;\n",
    "DUMP y;\n",
    "STORE y INTO 'output';\n",
    "fs -get output/ .;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
